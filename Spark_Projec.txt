text1 = sc.textFile(“/user/lab/full_text.txt”)
text2 = sc.textFile(“/user/lab/shakespeare.txt”)
text3 = sc.textFile(“/user/lab/number_list.txt”)

Q. 1
numbers = text3.flatMap(lambda line: line.split( ))
odd = numbers.filter(lambda x: int(x) % 2 != 0)
odd.take(5) 
odd.count()
Ans: 479

even = numbers.filter(lambda x: int(x) % 2 == 0)
even.take(5) 
even.count()
Ans: 521


Q. 2
words = text2.flatMap(lambda line: line.split())
words.take(10)
from operator import add
wordnick = words.map(lambda word: (word, 1)).reduceByKey(add)
wordnick.take(10)

(for a frequency count of all words in ascending order)
wordsum = wordnick.sortBy(lambda x: x[1]).collect()

(For, 10 words with lowest counts)
wordsum1 = wordnick.sortBy(lambda x: x[1]).take(10)
print wordsum1

(For, 10 words with highest counts)
wordsum2 = wordnick.sortBy(lambda x: -x[1]).take(10)
print wordsum2


Alternate Answer (PIG style Spark code)
a = sc.textFile(“/user/lab/shakespeare.txt”)
b = a.flatMap(lambda line: line.split())
c = b.map(lambda word: (word, 1))
d = c.reduceByKey(lambda v1, v2: v1+v2)
(for 10 lowest counts)
e = d.sortBy(lambda x: x[1]).take(10)
print e
(for 10 highest counts)
f = d.sortBy(lambda x: -x[1]).take(10)
print f
(May verify that the results are same as above)
Q. 3 
Ans (PIG Style Spark Coding)
a1 = sc.textFile(“/user/lab/full_text.txt”)
b1 = a1.flatMap(lambda line: line.split(“USER_”))
c1 = b1.map(lambda USER: (USER, 1))
d1 = c1.reduceByKey(lambda, v1, v2: v1+v2)
(to verify)
e1 = d1.sortBy(lambda x: -x[1]).take(10)   
f1 = d1.sortBy(lambda x: -x[1])
f1.saveAsTextFile(“CountTweet.txt”)

Alternate Ans:
text1.take(2)
tweet = text1.flatMap(lambda line: line.split(“USER_”))
from operator import add
tweetcount = tweet.map(lambda USER: (USER, 1)).reduceByKey(add)
tweetsort = tweetcount.sortBy(lambda x: -x[1])
tweetsort.saveAsTextFile(“Tweet_Count.txt”)


